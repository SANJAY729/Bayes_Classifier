{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvENABU-ZmOZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import copy\n",
        "from pprint import pprint\n",
        "from math import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import decomposition\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsOQfuT1O6qx"
      },
      "source": [
        "#Importing dataset\n",
        "dataset = pd.read_csv('Train_E.csv')\n",
        "\n",
        "#Handling missing values...\n",
        "dataset = dataset.fillna(dataset.mean())\n",
        "\n",
        "#Dropping date...\n",
        "dataset = dataset.drop(['date'], axis = 1)\n",
        "\n",
        "#One Hot Encoding for categorical columns (iso_code, continent, location)...\n",
        "dummy_iso_code = pd.get_dummies(dataset['iso_code'], prefix = \"iso_code\")\n",
        "dummy_continent = pd.get_dummies(dataset['continent'], prefix = \"continent\")\n",
        "dummy_location = pd.get_dummies(dataset['location'], prefix = \"location\")\n",
        "dataset = pd.concat([dummy_location, dataset], axis = 1)\n",
        "dataset = pd.concat([dummy_continent, dataset], axis = 1)\n",
        "dataset = pd.concat([dummy_iso_code, dataset], axis = 1)\n",
        "dataset = dataset.drop(['iso_code', 'continent', 'location'], axis = 1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC-K4CsE6YHa"
      },
      "source": [
        "#splits dataset into train, test in ratio 80:20 and does normalization on data\n",
        "def train_test_split(s_dataset):\n",
        "    features = s_dataset.columns\n",
        "    k = int(len(s_dataset.index)*0.8)\n",
        "    training_data = s_dataset.iloc[:k].reset_index(drop=True)\n",
        "    testing_data = s_dataset.iloc[k:].reset_index(drop=True)\n",
        "    scalar = preprocessing.StandardScaler()\n",
        "    training_data = scalar.fit_transform(training_data)\n",
        "    testing_data = scalar.transform(testing_data)\n",
        "    return pd.DataFrame(data = training_data, columns = features), pd.DataFrame(data = testing_data, columns = features)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCFg50GQ7jdF"
      },
      "source": [
        "#random shuffle and splitting data into train, test\n",
        "dataset = dataset.sample(frac = 1, random_state = 0).reset_index(drop = True)\n",
        "training_data,testing_data = train_test_split(dataset)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZSExDkGDgl7"
      },
      "source": [
        "#makes validation, train sets for k fold cross validation\n",
        "def k_fold_validation(training_data,k):\n",
        "    train_list = list()\n",
        "    validation_list = list()\n",
        "    l = len(training_data.index)\n",
        "    fold = int(l/k)\n",
        "    for i in range(k):\n",
        "      validation_list.append(training_data.iloc[i*fold:(i+1)*int(l/k)].reset_index(drop = True))\n",
        "      train_copy = copy.deepcopy(training_data)\n",
        "      train_list.append(train_copy.drop(train_copy.index[i*fold:(i+1)*int(l/k)]).reset_index(drop = True))\n",
        "    return train_list,validation_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwgYiWkVKD_i"
      },
      "source": [
        "train_list,validation_list = k_fold_validation(training_data,5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROQJ1H-YHTMD"
      },
      "source": [
        "def summary_util(train_data):\n",
        "    result = list()\n",
        "    attributes = train_data.columns\n",
        "    for attribute in attributes:\n",
        "      if (attribute != 'life_expectancy'):\n",
        "        result.append([train_data[attribute].mean(), train_data[attribute].std()])\n",
        "    return result\n",
        "\n",
        "def summary(train_data):\n",
        "    l = len(train_data.index)\n",
        "    result = {}\n",
        "    classes = train_data['life_expectancy'].unique()\n",
        "    freq = train_data['life_expectancy'].value_counts()\n",
        "    prior_probs = {}\n",
        "    for label in classes:\n",
        "        prior_probs[label] = freq[label]/l;\n",
        "        result[label] = summary_util(train_data[train_data['life_expectancy'] == label])\n",
        "    return result,prior_probs\n",
        "\n",
        "def gaussian(x, mean, stdev):\n",
        "    if stdev == 0:\n",
        "      return float(x == mean)\n",
        "    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
        "    return (1 / (sqrt(2 * pi) * stdev)) * exponent  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAx4zUg2uuMj"
      },
      "source": [
        "def probability(row,summ_by_class,freq):\n",
        "  prob = 1.0\n",
        "  i = 0\n",
        "  for item in row.index:\n",
        "    if(item != 'life_expectancy'):\n",
        "      p=gaussian(row[item],summ_by_class[i][0],summ_by_class[i][1])\n",
        "      if p==0:\n",
        "        prob *=float(1.0/freq) #laplacian correction\n",
        "      else:\n",
        "        prob*=p\n",
        "      i += 1      \n",
        "  return prob"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEmNW392lYXf"
      },
      "source": [
        "def test(train_data,test_data):\n",
        "  sep_class,prior_probs=summary(train_data)\n",
        "  predicted_class=[]\n",
        "  freq = train_data['life_expectancy'].value_counts()\n",
        "  for i,row in test_data.iterrows():\n",
        "    prob_by_class={}   \n",
        "    #print(row)\n",
        "    for item in sep_class:      \n",
        "      prob_by_class[item]=probability(row,sep_class[item],freq[item])*prior_probs[item]\n",
        "    predicted_class.append(max(prob_by_class, key=prob_by_class.get))\n",
        "  return predicted_class"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rvVmY873EK3"
      },
      "source": [
        "def accuracy(train_data,test_data):\n",
        "  predicted_classes = test(train_data,test_data)\n",
        "  correct = 0\n",
        "  for i in range(len(predicted_classes)):\n",
        "    if predicted_classes[i] == test_data['life_expectancy'][i]:\n",
        "      correct += 1\n",
        "  return 100*correct/len(predicted_classes)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I141mTs8xuJx",
        "outputId": "0c964e69-1f23-4e8d-bdf2-e5621ccdca2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print('validation-accuracy for set'+ str(i+1)+': '+str(accuracy(train_list[i],validation_list[i])))\n",
        "print('test-accuracy: '+str(accuracy(train_list[0],testing_data))) # any of the 5 may be used as all give 100% accuracy on validation set."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation-accuracy for set1: 100.0\n",
            "validation-accuracy for set2: 100.0\n",
            "validation-accuracy for set3: 100.0\n",
            "validation-accuracy for set4: 100.0\n",
            "validation-accuracy for set5: 100.0\n",
            "test-accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7XN72uZhZD",
        "outputId": "40a2dc7b-5f7c-4ef0-80d3-84f161bfedd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "#Applying PCA on processed data after normalization\n",
        "dataset = dataset.sample(frac = 1, random_state = 0).reset_index(drop = True)\n",
        "training_pca,testing_pca = train_test_split(dataset)\n",
        "\n",
        "train_X = copy.deepcopy(training_pca)\n",
        "train_X = train_X.drop(['life_expectancy'], axis = 1)\n",
        "train_Y = copy.deepcopy(training_pca)\n",
        "train_Y = train_Y['life_expectancy']\n",
        "test_X = copy.deepcopy(testing_pca)\n",
        "test_X = test_X.drop(['life_expectancy'], axis = 1)\n",
        "test_Y = copy.deepcopy(testing_pca)\n",
        "test_Y = test_Y['life_expectancy']\n",
        "\n",
        "pc_columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17',\n",
        "              'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34']\n",
        "\n",
        "pca = decomposition.PCA()\n",
        "pc = pca.fit_transform(train_X)\n",
        "\n",
        "test_X = pca.transform(test_X)\n",
        "\n",
        "pc_df_train = pd.DataFrame(data = pc, columns = pc_columns)\n",
        "pc_df_train['life_expectancy'] = train_Y\n",
        "pc_df_test = pd.DataFrame(data = test_X, columns = pc_columns)\n",
        "pc_df_test['life_expectancy'] = test_Y\n",
        "\n",
        "#print(pca.explained_variance_ratio_)\n",
        "\n",
        "fig = plt.figure(figsize = (20,10))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(pc_columns, pca.explained_variance_ratio_)\n",
        "plt.show()\n",
        "\n",
        "i = 0\n",
        "var = 0\n",
        "while (var<0.95):\n",
        "  var += pca.explained_variance_ratio_[i]\n",
        "  i += 1\n",
        "print(\"The number of components to be used is \" + str(i))\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The number of components to be used is 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "espgl-1fNOn3",
        "outputId": "9e568a92-f20e-4608-bf00-5d3252883c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Performing 5-fold cross validation on the new dataset obtained after performing PCA\n",
        "pc_df_train = pc_df_train[['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'life_expectancy']]\n",
        "pc_df_test = pc_df_test[['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'life_expectancy']]\n",
        "pc_train_list,pc_validation_list = k_fold_validation(pc_df_train,5)\n",
        "for i in range(5):\n",
        "  print('pc_validation-accuracy for set'+ str(i+1)+': '+str(accuracy(pc_train_list[i],pc_validation_list[i])))\n",
        "print('pc_test-accuracy: '+str(accuracy(pc_train_list[0],pc_df_test))) # 0,2,3,4 may be used as they give highest accuracy on validation data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pc_validation-accuracy for set1: 100.0\n",
            "pc_validation-accuracy for set2: 98.93617021276596\n",
            "pc_validation-accuracy for set3: 100.0\n",
            "pc_validation-accuracy for set4: 100.0\n",
            "pc_validation-accuracy for set5: 100.0\n",
            "pc_test-accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1iwrP_fqfYO",
        "outputId": "aa6107e9-a9a7-49eb-94e4-27a4a1935615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Removing Outliers in Dataset\n",
        "training_data,testing_data = train_test_split(dataset) #splitting is done so as to normalize the data. (the procedure for normalization is included in train_test_split)\n",
        "features = ['total_cases', 'new_cases', 'new_cases_smoothed', 'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million',\n",
        "       'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million', 'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'stringency_index', 'population',\n",
        "       'population_density', 'median_age', 'aged_65_older', 'aged_70_older', 'gdp_per_capita', 'diabetes_prevalence']\n",
        "mean = []\n",
        "stddev = []\n",
        "for col in features:\n",
        "  mean.append(pd.concat([training_data, testing_data])[col].mean())\n",
        "  stddev.append(pd.concat([training_data, testing_data])[col].std())\n",
        "new_train = pd.DataFrame(columns = training_data.columns)\n",
        "for id in training_data.index:\n",
        "  i = 0\n",
        "  flag = 0\n",
        "  for col in features:\n",
        "    if (abs(training_data[col][id] - mean[i]) >3*stddev[i]):\n",
        "      flag = flag + 1\n",
        "    i = i + 1\n",
        "  if (flag <= 2):\n",
        "    new_train.loc[len(new_train)] = training_data.loc[id]\n",
        "\n",
        "new_test = pd.DataFrame(columns = testing_data.columns)\n",
        "for id in testing_data.index:\n",
        "  i = 0\n",
        "  flag = 0\n",
        "  for col in features:\n",
        "    if (abs(testing_data[col][id] - mean[i]) > 3*stddev[i]):\n",
        "      flag = flag + 1\n",
        "    i = i + 1\n",
        "  if (flag <= 2):\n",
        "    new_test.loc[len(new_test)] = testing_data.loc[id]\n",
        "\n",
        "\n",
        "train_list,validation_list = k_fold_validation(new_train,5)\n",
        "print('Number of samples removed from training data: ',len(training_data)-len(new_train))\n",
        "print('Number of samples removed from training data: ',len(testing_data)-len(new_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples removed from training data:  43\n",
            "Number of samples removed from training data:  12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pud0sRd2uxN1",
        "outputId": "9a50bb18-d4e7-440c-e598-5faa71ae36ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Performing Sequential Backward Selection Algorithm\n",
        "j = 0\n",
        "train_data = copy.deepcopy(train_list)\n",
        "val_data = copy.deepcopy(validation_list)\n",
        "while 1:\n",
        "  j += 1  \n",
        "  curr_acc = 0\n",
        "  for i in range(5):\n",
        "    curr_acc += accuracy(train_data[i],val_data[i])\n",
        "  curr_acc /= 5\n",
        "  print('Dropping feature no.'+str(j),end=' ')\n",
        "  col_kick = None\n",
        "  for column in train_data[0]:\n",
        "    print('.',end = '')\n",
        "    if column == 'life_expectancy':\n",
        "      continue\n",
        "    temp_acc = 0\n",
        "    for i in range(5):\n",
        "      temp_train = copy.deepcopy(train_data[i])\n",
        "      temp_test = copy.deepcopy(val_data[i])\n",
        "      temp_train = temp_train.drop([column],axis=1)\n",
        "      temp_test = temp_test.drop([column],axis=1)\n",
        "      temp_acc += accuracy(temp_train,temp_test)\n",
        "    if temp_acc/5 >= curr_acc:\n",
        "      curr_acc = temp_acc\n",
        "      col_kick = column\n",
        "  if col_kick != None:\n",
        "    print(\"\\nDropped: \"+col_kick,end='\\n\\n')\n",
        "    for i in range(5):\n",
        "      train_data[i] = train_data[i].drop([col_kick],axis=1)\n",
        "      val_data[i] = val_data[i].drop([col_kick],axis=1)\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dropping feature no.1 ...................................\n",
            "Dropped: iso_code_ABW\n",
            "\n",
            "Dropping feature no.2 ..................................\n",
            "Dropped: iso_code_AFG\n",
            "\n",
            "Dropping feature no.3 .................................\n",
            "Dropped: iso_code_AGO\n",
            "\n",
            "Dropping feature no.4 ................................\n",
            "Dropped: iso_code_ALB\n",
            "\n",
            "Dropping feature no.5 ...............................\n",
            "Dropped: iso_code_ARE\n",
            "\n",
            "Dropping feature no.6 ..............................\n",
            "Dropped: continent_Africa\n",
            "\n",
            "Dropping feature no.7 .............................\n",
            "Dropped: continent_Asia\n",
            "\n",
            "Dropping feature no.8 ............................\n",
            "Dropped: continent_Europe\n",
            "\n",
            "Dropping feature no.9 ...........................\n",
            "Dropped: continent_North America\n",
            "\n",
            "Dropping feature no.10 ..........................\n",
            "Dropped: location_Afghanistan\n",
            "\n",
            "Dropping feature no.11 .........................\n",
            "Dropped: location_Albania\n",
            "\n",
            "Dropping feature no.12 ........................\n",
            "Dropped: location_Angola\n",
            "\n",
            "Dropping feature no.13 .......................\n",
            "Dropped: total_cases\n",
            "\n",
            "Dropping feature no.14 ......................\n",
            "Dropped: new_cases\n",
            "\n",
            "Dropping feature no.15 .....................\n",
            "Dropped: new_cases_smoothed\n",
            "\n",
            "Dropping feature no.16 ....................\n",
            "Dropped: location_United Arab Emirates\n",
            "\n",
            "Dropping feature no.17 ...................\n",
            "Dropped: total_deaths\n",
            "\n",
            "Dropping feature no.18 ..................\n",
            "Dropped: new_deaths\n",
            "\n",
            "Dropping feature no.19 .................\n",
            "Dropped: new_deaths_smoothed\n",
            "\n",
            "Dropping feature no.20 ................\n",
            "Dropped: location_Aruba\n",
            "\n",
            "Dropping feature no.21 ...............\n",
            "Dropped: total_cases_per_million\n",
            "\n",
            "Dropping feature no.22 ..............\n",
            "Dropped: new_cases_per_million\n",
            "\n",
            "Dropping feature no.23 .............\n",
            "Dropped: new_cases_smoothed_per_million\n",
            "\n",
            "Dropping feature no.24 ............\n",
            "Dropped: total_deaths_per_million\n",
            "\n",
            "Dropping feature no.25 ...........\n",
            "Dropped: new_deaths_per_million\n",
            "\n",
            "Dropping feature no.26 ..........\n",
            "Dropped: new_deaths_smoothed_per_million\n",
            "\n",
            "Dropping feature no.27 .........\n",
            "Dropped: stringency_index\n",
            "\n",
            "Dropping feature no.28 ........\n",
            "Dropped: population\n",
            "\n",
            "Dropping feature no.29 .......\n",
            "Dropped: population_density\n",
            "\n",
            "Dropping feature no.30 ......\n",
            "Dropped: median_age\n",
            "\n",
            "Dropping feature no.31 .....\n",
            "Dropped: aged_65_older\n",
            "\n",
            "Dropping feature no.32 ....\n",
            "Dropped: aged_70_older\n",
            "\n",
            "Dropping feature no.33 ...\n",
            "Dropped: gdp_per_capita\n",
            "\n",
            "Dropping feature no.34 .."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btsfn-OlfEHu",
        "outputId": "f50a5bff-4df9-4624-dbd2-b07304f1d77a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Printing the features remaining \n",
        "print('Features remaining:',end=' ')\n",
        "for column in train_data[0]:\n",
        "    if column=='life_expectancy':\n",
        "      continue\n",
        "    print(column,end=' ')\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features remaining: diabetes_prevalence "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkonrTDYg5D1",
        "outputId": "5404c533-e9e2-439d-8643-b7e7e3303470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Performing 5-fold cross validation on the new dataset obtained after performing Sequential Backward Selection Algorithm\n",
        "dataset_SBS = copy.deepcopy(pd.concat([new_train, new_test]))\n",
        "dataset_SBS = dataset_SBS[['diabetes_prevalence', 'life_expectancy']]\n",
        "dataset_SBS = dataset_SBS.sample(frac = 1, random_state = 0).reset_index(drop = True)\n",
        "sbs_training_data,sbs_testing_data = train_test_split(dataset_SBS)\n",
        "sbs_train_list,sbs_validation_list = k_fold_validation(sbs_training_data,5)\n",
        "for i in range(5):\n",
        "  print('sbs_validation-accuracy for set'+ str(i+1)+': '+str(accuracy(sbs_train_list[i],sbs_validation_list[i])))\n",
        "print('sbs_test-accuracy: '+str(accuracy(sbs_train_list[0],sbs_testing_data))) # any of the 5 may be used as all give 100% accuracy on validation set."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sbs_validation-accuracy for set1: 100.0\n",
            "sbs_validation-accuracy for set2: 100.0\n",
            "sbs_validation-accuracy for set3: 100.0\n",
            "sbs_validation-accuracy for set4: 100.0\n",
            "sbs_validation-accuracy for set5: 100.0\n",
            "sbs_test-accuracy: 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}